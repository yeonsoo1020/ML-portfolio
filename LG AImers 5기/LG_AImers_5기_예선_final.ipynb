{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f9f9cce1",
      "metadata": {
        "id": "f9f9cce1"
      },
      "source": [
        "# 제품 이상 여부 판별 프로젝트"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36316b6b",
      "metadata": {
        "id": "36316b6b"
      },
      "source": [
        "# 1. 데이터 & 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HVNx8uUTEULd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVNx8uUTEULd",
        "outputId": "457324e1-99eb-40d1-8722-3200818ce34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: catboost in ./.local/lib/python3.10/site-packages (1.2)\n",
            "Requirement already satisfied: graphviz in ./.local/lib/python3.10/site-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from catboost) (3.9.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in ./.local/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in ./.local/lib/python3.10/site-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from catboost) (1.14.0)\n",
            "Requirement already satisfied: plotly in ./.local/lib/python3.10/site-packages (from catboost) (5.23.0)\n",
            "Requirement already satisfied: six in ./.local/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in ./.local/lib/python3.10/site-packages (from plotly->catboost) (9.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e0066d",
      "metadata": {
        "id": "b1e0066d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import warnings; warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.max_columns',100)\n",
        "pd.set_option('display.max_rows',100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "411f29f7",
      "metadata": {
        "id": "411f29f7"
      },
      "source": [
        "### 데이터 읽어오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b825e37b",
      "metadata": {
        "id": "b825e37b",
        "outputId": "d77176e1-702f-4ff3-cd22-24571f5236e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape :  (40506, 464)\n",
            "test shape :  (17361, 465)\n"
          ]
        }
      ],
      "source": [
        "ROOT_DIR = \"data\"\n",
        "RANDOM_STATE = 77\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv(os.path.join(\"train.csv\"))\n",
        "test_data = pd.read_csv(os.path.join(\"test.csv\"))\n",
        "print(\"train shape : \", train_data.shape)\n",
        "print(\"test shape : \", test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bd8a22",
      "metadata": {
        "id": "46bd8a22"
      },
      "source": [
        "# 2. 데이터 전처리 - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c0e8cf",
      "metadata": {
        "id": "c6c0e8cf"
      },
      "source": [
        "### Null값 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c05d3a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "0c05d3a3",
        "outputId": "e0d2af44-9896-40ea-d6cb-13d3c911987a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Wip Line_Dam                         0\n",
              "Process Desc._Dam                    0\n",
              "Equipment_Dam                        0\n",
              "Model.Suffix_Dam                     0\n",
              "Workorder_Dam                        0\n",
              "                                 ...  \n",
              "Receip No Judge Value_Fill2      40506\n",
              "WorkMode Collect Result_Fill2        0\n",
              "WorkMode Unit Time_Fill2         40506\n",
              "WorkMode Judge Value_Fill2       40506\n",
              "target                               0\n",
              "Length: 464, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e3c5dec",
      "metadata": {
        "id": "9e3c5dec"
      },
      "source": [
        "### Null이 50%이상인 컬럼제거\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c90777b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c90777b7",
        "outputId": "f5ea51f8-276a-4258-8c88-ccdad8ea75d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape :  (40506, 181)\n"
          ]
        }
      ],
      "source": [
        "# Null 값이 포함된 컬럼만 추출\n",
        "null_columns = train_data.columns[train_data.isna().any()]\n",
        "\n",
        "# Null 값이 포함된 컬럼들의 null 값 개수 확인\n",
        "null_counts = train_data[null_columns].isna().sum()\n",
        "\n",
        "# Drop columns with more than half of the values missing\n",
        "drop_cols = []\n",
        "for column in train_data.columns:\n",
        "    if (train_data[column].notnull().sum() // 2) < train_data[\n",
        "        column\n",
        "    ].isnull().sum():\n",
        "        drop_cols.append(column)\n",
        "train_data = train_data.drop(drop_cols, axis=1)\n",
        "print(\"train shape : \", train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a72d1e0",
      "metadata": {
        "id": "7a72d1e0"
      },
      "outputs": [],
      "source": [
        "features = []\n",
        "for col in train_data.columns:\n",
        "    try:\n",
        "        features.append(col)\n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f39b1950",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f39b1950",
        "outputId": "ed946ee8-041d-4013-893a-7aabe0e9c56f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test shape :  (17361, 181)\n"
          ]
        }
      ],
      "source": [
        "test_data = test_data[features]\n",
        "print(\"test shape : \", test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee00c16d",
      "metadata": {
        "id": "ee00c16d"
      },
      "source": [
        "# 3. 데이터 전처리 - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d1387ca",
      "metadata": {
        "id": "9d1387ca"
      },
      "source": [
        "### 다시 NULL값 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9690c590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "9690c590",
        "outputId": "a221e5e0-01d3-4835-bf5c-0c08c71a13fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam      12766\n",
              "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1    12766\n",
              "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2    12766\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값이 포함된 컬럼만 추출\n",
        "null_columns = train_data.columns[train_data.isna().any()]\n",
        "\n",
        "# Null 값이 포함된 컬럼들의 null 값 개수 확인\n",
        "null_counts = train_data[null_columns].isna().sum()\n",
        "\n",
        "null_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75adb1df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75adb1df",
        "outputId": "12fe4014-23d0-4d21-ee2d-96eff55511fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in column 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam':\n",
            "[nan '550.3' 'OK' '162.4' '549' '549.5' '550' '548.5']\n",
            "\n",
            "Unique values in column 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1':\n",
            "[nan '838.4' 'OK' '837.7' '837.9' '838.2' '837.5']\n",
            "\n",
            "Unique values in column 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2':\n",
            "[nan '835.5' 'OK' '305']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 컬럼 이름 설정\n",
        "columns_of_interest = [\n",
        "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
        "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
        "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'\n",
        "]\n",
        "\n",
        "# 각 컬럼의 유니크 값 찾기\n",
        "for column in columns_of_interest:\n",
        "    unique_values = train_data[column].unique()\n",
        "    print(f\"Unique values in column '{column}':\")\n",
        "    print(unique_values)\n",
        "    print()  # 빈 줄 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e26680df",
      "metadata": {
        "id": "e26680df"
      },
      "source": [
        "NULL, 숫자형, 범주형 변수가 섞여있음 -> 데이터가 밀린것을 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da8aaf9c",
      "metadata": {
        "id": "da8aaf9c"
      },
      "source": [
        "### 데이터 밀려있는부분 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f85ba3",
      "metadata": {
        "id": "a9f85ba3"
      },
      "source": [
        "#### Train - Dam 밀린부분 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afac3831",
      "metadata": {
        "id": "afac3831"
      },
      "outputs": [],
      "source": [
        "# Dam 안밀린부분 떼어내기\n",
        "D0 = train_data.iloc[:, :24]\n",
        "\n",
        "# Dam 밀린부분 작업해주기\n",
        "Dam1 = train_data[(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] == \"OK\") |\n",
        "                  (pd.isna(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam']))]\n",
        "Dam2 = train_data[(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] != \"OK\") &\n",
        "                  (~pd.isna(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam']))]\n",
        "\n",
        "Dam_col = train_data.columns[24:77]\n",
        "\n",
        "D1 = Dam1[Dam_col]\n",
        "D1 = D1.iloc[:, 1:]\n",
        "D1['new'] = 7\n",
        "D1.columns = Dam_col\n",
        "D2 = Dam2[Dam_col]\n",
        "D = pd.concat([D1, D2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8647a617",
      "metadata": {
        "id": "8647a617"
      },
      "source": [
        "#### Train - AutoClave 밀린부분 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5918b5",
      "metadata": {
        "id": "9c5918b5"
      },
      "outputs": [],
      "source": [
        "# Auto Clave는 안밀려있음\n",
        "Auto = train_data.iloc[:, 77:96]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b1c8ae5",
      "metadata": {
        "id": "2b1c8ae5"
      },
      "source": [
        "#### Train - Fill1 밀린부분 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64b3648",
      "metadata": {
        "id": "a64b3648"
      },
      "outputs": [],
      "source": [
        "# Fill1 안밀린부분 작업해주기\n",
        "F1_0 = train_data.iloc[:, 96:110]\n",
        "\n",
        "# Fill1 밀린부분 작업해주기\n",
        "Fill1_1 = train_data[(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] == \"OK\") |\n",
        "               (pd.isna(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1']))]\n",
        "Fill1_2 = train_data[(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] != \"OK\") &\n",
        "               (~pd.isna(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1']))]\n",
        "\n",
        "Fill1_col = train_data.columns[110:133]\n",
        "Fill1_col\n",
        "F1_1 = Fill1_1[Fill1_col]\n",
        "F1_1 = F1_1.iloc[:, 1:]\n",
        "F1_1['new'] = 7\n",
        "F1_1.columns = Fill1_col\n",
        "F1_2 = Fill1_2[Fill1_col]\n",
        "FF1 = pd.concat([F1_1, F1_2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce08aad",
      "metadata": {
        "id": "5ce08aad"
      },
      "source": [
        "#### Train - Fill2 밀린부분 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e284f19",
      "metadata": {
        "id": "4e284f19"
      },
      "outputs": [],
      "source": [
        "# Fill2 안밀린부분 작업해주기\n",
        "F2_0 = train_data.iloc[:, 133:157]\n",
        "F2_0\n",
        "# Fill2 밀린부분 작업해주기\n",
        "Fill2_1 = train_data[(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] == \"OK\") |\n",
        "               (pd.isna(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2']))]\n",
        "Fill2_2 = train_data[(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] != \"OK\") &\n",
        "               (~pd.isna(train_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2']))]\n",
        "\n",
        "Fill2_col = train_data.columns[157:180]\n",
        "\n",
        "F2_1 = Fill2_1[Fill2_col]\n",
        "F2_1 = F2_1.iloc[:, 1:]\n",
        "F2_1['new'] = 0\n",
        "F2_1.columns = Fill2_col\n",
        "F2_2 = Fill2_2[Fill2_col]\n",
        "FF2 = pd.concat([F2_1, F2_2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2020eb6e",
      "metadata": {
        "id": "2020eb6e"
      },
      "source": [
        "### Train data 병합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d06726",
      "metadata": {
        "id": "d1d06726"
      },
      "outputs": [],
      "source": [
        "# target\n",
        "target = train_data.iloc[:, 180]\n",
        "\n",
        "# 병합\n",
        "train_data = pd.concat([D0, D, Auto, F1_0, FF1, F2_0, FF2, target], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967f9f2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "967f9f2f",
        "outputId": "82cd8ab3-1472-48c3-a253-0f38529553d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Series([], dtype: float64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값이 포함된 컬럼만 추출\n",
        "null_columns = train_data.columns[train_data.isna().any()]\n",
        "\n",
        "# Null 값이 포함된 컬럼들의 null 값 개수 확인\n",
        "null_counts = train_data[null_columns].isna().sum()\n",
        "\n",
        "null_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c169ef1b",
      "metadata": {
        "id": "c169ef1b"
      },
      "source": [
        "NULL 값이 없는것을 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cbafc8b",
      "metadata": {
        "id": "4cbafc8b"
      },
      "source": [
        "### Test data도 동일하게 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7ecea9",
      "metadata": {
        "id": "2a7ecea9"
      },
      "outputs": [],
      "source": [
        "# Dam 안밀린부분 떼어내기\n",
        "D0 = test_data.iloc[:, :24]\n",
        "\n",
        "# Dam 밀린부분 작업해주기\n",
        "Dam1 = test_data[(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] == \"OK\") |\n",
        "                  (pd.isna(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam']))]\n",
        "Dam2 = test_data[(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] != \"OK\") &\n",
        "                  (~pd.isna(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam']))]\n",
        "\n",
        "Dam_col = test_data.columns[24:77]\n",
        "\n",
        "D1 = Dam1[Dam_col]\n",
        "D1 = D1.iloc[:, 1:]\n",
        "D1['new'] = 7\n",
        "D1.columns = Dam_col\n",
        "D2 = Dam2[Dam_col]\n",
        "D = pd.concat([D1, D2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971394f5",
      "metadata": {
        "id": "971394f5"
      },
      "outputs": [],
      "source": [
        "# Auto Clave는 안밀려있음\n",
        "Auto = test_data.iloc[:, 77:96]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820e766b",
      "metadata": {
        "id": "820e766b"
      },
      "outputs": [],
      "source": [
        "# Fill1 안밀린부분 작업해주기\n",
        "F1_0 = test_data.iloc[:, 96:110]\n",
        "\n",
        "# Fill1 밀린부분 작업해주기\n",
        "Fill1_1 = test_data[(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] == \"OK\") |\n",
        "               (pd.isna(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1']))]\n",
        "Fill1_2 = test_data[(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] != \"OK\") &\n",
        "               (~pd.isna(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1']))]\n",
        "\n",
        "Fill1_col = test_data.columns[110:133]\n",
        "Fill1_col\n",
        "F1_1 = Fill1_1[Fill1_col]\n",
        "F1_1 = F1_1.iloc[:, 1:]\n",
        "F1_1['new'] = 7\n",
        "F1_1.columns = Fill1_col\n",
        "F1_2 = Fill1_2[Fill1_col]\n",
        "FF1 = pd.concat([F1_1, F1_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe983a9d",
      "metadata": {
        "id": "fe983a9d"
      },
      "outputs": [],
      "source": [
        "# Fill2 안밀린부분 작업해주기\n",
        "F2_0 = test_data.iloc[:, 133:157]\n",
        "F2_0\n",
        "# Fill2 밀린부분 작업해주기\n",
        "Fill2_1 = test_data[(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] == \"OK\") |\n",
        "               (pd.isna(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2']))]\n",
        "Fill2_2 = test_data[(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] != \"OK\") &\n",
        "               (~pd.isna(test_data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2']))]\n",
        "\n",
        "Fill2_col = test_data.columns[157:180]\n",
        "\n",
        "F2_1 = Fill2_1[Fill2_col]\n",
        "F2_1 = F2_1.iloc[:, 1:]\n",
        "F2_1['new'] = 0\n",
        "F2_1.columns = Fill2_col\n",
        "F2_2 = Fill2_2[Fill2_col]\n",
        "FF2 = pd.concat([F2_1, F2_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb40e4bb",
      "metadata": {
        "id": "bb40e4bb"
      },
      "outputs": [],
      "source": [
        "# 병합\n",
        "test_data = pd.concat([D0, D, Auto, F1_0, FF1, F2_0, FF2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea763a8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "ea763a8d",
        "outputId": "a5f5ba04-f949-40a5-c97d-3b6fbcda39c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Series([], dtype: float64)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값이 포함된 컬럼만 추출\n",
        "null_columns = test_data.columns[test_data.isna().any()]\n",
        "\n",
        "# Null 값이 포함된 컬럼들의 null 값 개수 확인\n",
        "null_counts = test_data[null_columns].isna().sum()\n",
        "\n",
        "null_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HX_9EppoB8s5",
      "metadata": {
        "id": "HX_9EppoB8s5"
      },
      "source": [
        "### 데이터 타입 통일"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gw2iVw4CCHes",
      "metadata": {
        "id": "gw2iVw4CCHes"
      },
      "outputs": [],
      "source": [
        "# 숫자형과 문자열이 섞여있는 열을 찾고 숫자형으로 변환\n",
        "for column in train_data.columns:\n",
        "    if train_data[column].apply(lambda x: isinstance(x, (int, float))).any() and train_data[column].apply(lambda x: isinstance(x, str)).any():\n",
        "        train_data[column] = pd.to_numeric(train_data[column], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A1EYNoLgCHhI",
      "metadata": {
        "id": "A1EYNoLgCHhI"
      },
      "outputs": [],
      "source": [
        "# 숫자형과 문자열이 섞여있는 열을 찾고 숫자형으로 변환\n",
        "for column in test_data.columns:\n",
        "    if test_data[column].apply(lambda x: isinstance(x, (int, float))).any() and test_data[column].apply(lambda x: isinstance(x, str)).any():\n",
        "        test_data[column] = pd.to_numeric(test_data[column], errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d250cda",
      "metadata": {
        "id": "1d250cda"
      },
      "source": [
        "# 4. 데이터 전처리 - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca128927",
      "metadata": {
        "id": "ca128927",
        "outputId": "6ed5d8f5-5f35-4e49-8e7e-5c7810738344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40506, 113)\n",
            "(17361, 112)\n"
          ]
        }
      ],
      "source": [
        "# 불필요한 변수 제거\n",
        "def variable_cleanup(data):\n",
        "    # Workorder\n",
        "    data_cleaned = data.drop(columns=['Workorder_Fill1', 'Workorder_AutoClave', 'Workorder_Fill2'])\n",
        "    data_cleaned = data_cleaned.rename(columns={'Workorder_Dam': 'Workorder'})\n",
        "\n",
        "    # Model.Suffix\n",
        "    data_cleaned = data_cleaned.drop(columns=['Model.Suffix_Fill1', 'Model.Suffix_AutoClave', 'Model.Suffix_Fill2'])\n",
        "    data_cleaned = data_cleaned.rename(columns={'Model.Suffix_Dam': 'Model.Suffix'})\n",
        "\n",
        "    # Wip Line, Process Desc, Insp. Seq No., Insp Judge Code, WorkMode , Equipment_AutoClave\n",
        "    data_cleaned = data_cleaned.drop(columns=[\n",
        "        'Wip Line_Dam', 'Wip Line_Fill1', 'Wip Line_AutoClave', 'Wip Line_Fill2',\n",
        "        'Process Desc._Dam', 'Process Desc._Fill1', 'Process Desc._AutoClave', 'Process Desc._Fill2',\n",
        "        'Insp. Seq No._Dam', 'Insp. Seq No._Fill1', 'Insp. Seq No._AutoClave', 'Insp. Seq No._Fill2',\n",
        "        'Insp Judge Code_Dam', 'Insp Judge Code_Fill1', 'Insp Judge Code_AutoClave', 'Insp Judge Code_Fill2',\n",
        "        'WorkMode Collect Result_Dam', 'WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2',\n",
        "        'Equipment_AutoClave'\n",
        "    ])\n",
        "\n",
        "    # unique value = 0 또는 OK (only, 좌표 조합은 제외)\n",
        "    data_cleaned = data_cleaned.drop(columns=[\n",
        "        'DISCHARGED SPEED OF RESIN Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill2',\n",
        "        'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill2',\n",
        "        'Dispense Volume(Stage1) Collect Result_Fill2', 'Dispense Volume(Stage2) Collect Result_Fill2', 'Dispense Volume(Stage3) Collect Result_Fill2',\n",
        "        '1st Pressure Judge Value_AutoClave', '2nd Pressure Judge Value_AutoClave', '3rd Pressure Judge Value_AutoClave'\n",
        "    ])\n",
        "\n",
        "    # 새로운 column drop\n",
        "    data_cleaned = data_cleaned.drop(columns=[\n",
        "        'CURE STANDBY POSITION X Collect Result_Dam', 'CURE STANDBY POSITION Z Collect Result_Dam', 'CURE STANDBY POSITION Θ Collect Result_Dam',\n",
        "        'CURE START POSITION Z Collect Result_Dam',\n",
        "        'HEAD Standby Position X Collect Result_Dam', 'HEAD Standby Position Y Collect Result_Dam', 'HEAD Standby Position Z Collect Result_Dam',\n",
        "        'Head Clean Position X Collect Result_Dam', 'Head Clean Position Y Collect Result_Dam',\n",
        "        'Head Purge Position X Collect Result_Dam', 'Head Purge Position Y Collect Result_Dam',\n",
        "        'Head Zero Position X Collect Result_Dam',\n",
        "        'HEAD Standby Position X Collect Result_Fill1','HEAD Standby Position Y Collect Result_Fill1','HEAD Standby Position Z Collect Result_Fill1',\n",
        "        'Head Clean Position X Collect Result_Fill1','Head Clean Position Y Collect Result_Fill1','Head Clean Position Z Collect Result_Fill1',\n",
        "        'Head Purge Position X Collect Result_Fill1','Head Purge Position Y Collect Result_Fill1',\n",
        "        'CURE END POSITION Θ Collect Result_Fill2',\n",
        "        'CURE STANDBY POSITION X Collect Result_Fill2', 'CURE STANDBY POSITION Θ Collect Result_Fill2',\n",
        "        'CURE START POSITION Θ Collect Result_Fill2',\n",
        "        'HEAD Standby Position X Collect Result_Fill2','HEAD Standby Position Y Collect Result_Fill2','HEAD Standby Position Z Collect Result_Fill2',\n",
        "        'Head Clean Position X Collect Result_Fill2','Head Clean Position Y Collect Result_Fill2','Head Clean Position Z Collect Result_Fill2',\n",
        "        'Head Purge Position X Collect Result_Fill2','Head Purge Position Y Collect Result_Fill2'\n",
        "    ])\n",
        "\n",
        "    return data_cleaned\n",
        "\n",
        "train_data = variable_cleanup(train_data); test_data = variable_cleanup(test_data)\n",
        "print(train_data.shape); print(test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b62e497c",
      "metadata": {
        "id": "b62e497c"
      },
      "source": [
        "### Tact time 제외하고 모두 범주형 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea7d040",
      "metadata": {
        "id": "5ea7d040",
        "outputId": "9e1339fd-e7d0-4511-ddc4-2392f00e5a24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "109"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 범주형 및 연속형 변수 정의\n",
        "numerical_cols = ['Machine Tact time Collect Result_Fill2', 'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam']\n",
        "categorical_cols = list(set(train_data.columns) - set(numerical_cols) - set(['target']))\n",
        "target_col = 'target'\n",
        "\n",
        "len(categorical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3d590b2-12ce-411a-960c-1f709bd10748",
      "metadata": {
        "id": "c3d590b2-12ce-411a-960c-1f709bd10748",
        "outputId": "1e928cb5-d92b-4887-e636-3991a26d219b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(numerical_cols) + len(categorical_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b879fdff",
      "metadata": {
        "id": "b879fdff"
      },
      "source": [
        "### Train - Validation 구분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cace78fb",
      "metadata": {
        "id": "cace78fb"
      },
      "outputs": [],
      "source": [
        "# train set, validation set 구분\n",
        "train_data[categorical_cols] = train_data[categorical_cols].astype('str')\n",
        "test_data[categorical_cols] = test_data[categorical_cols].astype('str')\n",
        "train_data['target'] = train_data['target'].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
        "\n",
        "X = train_data.drop('target', axis=1)\n",
        "y = train_data['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b96feca",
      "metadata": {
        "id": "4b96feca"
      },
      "source": [
        "# 4. 모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa502cd9",
      "metadata": {
        "id": "aa502cd9"
      },
      "source": [
        "## Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75bd3348",
      "metadata": {
        "id": "75bd3348"
      },
      "outputs": [],
      "source": [
        "params1={'iterations': 658,\n",
        "        'depth': 5,\n",
        "        'learning_rate': 0.05082916242908085,\n",
        "        'class_weights': {0:1, 1:8.015222449552683},\n",
        "        'l2_leaf_reg': 7.510174770627344}\n",
        "params2={'iterations': 999,\n",
        "        'depth': 6,\n",
        "        'learning_rate': 0.03822382444156112,\n",
        "        'class_weights': {0:1, 1:8.637597152124888},\n",
        "        'l2_leaf_reg': 3.3559037547107047}\n",
        "params3={'iterations': 1021,\n",
        "        'depth': 6,\n",
        "        'learning_rate': 0.03815933742323573,\n",
        "        'class_weights': {0:1, 1:9.427611426765473},\n",
        "        'l2_leaf_reg': 3.631569570817471}\n",
        "params4={'iterations': 652,\n",
        "        'depth': 5,\n",
        "        'learning_rate': 0.036251727686565996,\n",
        "        'class_weights': {0:1, 1:8.809186925675473},\n",
        "        'l2_leaf_reg': 3.681415978241256}\n",
        "params5={'iterations': 791,\n",
        "        'depth': 4,\n",
        "        'learning_rate': 0.02698725907627657,\n",
        "        'class_weights': {0:1, 1:8.220711939778287},\n",
        "        'l2_leaf_reg': 5.490510494004826}\n",
        "params6={'iterations': 873,\n",
        "        'depth': 6,\n",
        "        'learning_rate': 0.058237302882905025,\n",
        "        'class_weights': {0:1, 1:8.57569158023923},\n",
        "        'l2_leaf_reg': 8.197147726760026}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc6a3dca",
      "metadata": {
        "id": "fc6a3dca"
      },
      "outputs": [],
      "source": [
        "model1 = CatBoostClassifier(**params1, cat_features=categorical_cols, random_state=77, verbose=0, early_stopping_rounds  = 150)\n",
        "model2 = CatBoostClassifier(**params2, cat_features=categorical_cols, random_state=77, verbose=0, early_stopping_rounds  = 150)\n",
        "model3 = CatBoostClassifier(**params3, cat_features=categorical_cols, random_state=77, verbose=0, early_stopping_rounds  = 150)\n",
        "model4 = CatBoostClassifier(**params4, cat_features=categorical_cols, random_state=77, verbose=0, early_stopping_rounds  = 150)\n",
        "model5 = CatBoostClassifier(**params5, cat_features=categorical_cols, random_state=77, verbose=0, early_stopping_rounds  = 150)\n",
        "model6 = CatBoostClassifier(**params6, cat_features=categorical_cols, random_state=77, verbose=0, early_stopping_rounds  = 150)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d980682",
      "metadata": {
        "id": "6d980682"
      },
      "source": [
        "# 5. Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35da0683",
      "metadata": {
        "id": "35da0683",
        "outputId": "5279df37-db64-4fa0-b443-da1624fffecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0\n",
              "0    16298\n",
              "1     1063\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# VotingClassifier 정의 (Soft Voting 사용)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('cat1', model1), ('cat2', model2), ('cat3', model3),\n",
        "               ('cat4', model4), ('cat5', model5), ('cat6', model6)\n",
        "               ],\n",
        "    voting='soft'  # soft, hard\n",
        "            )\n",
        "\n",
        "# VotingClassifier 학습\n",
        "voting_clf.fit(X, y)\n",
        "# 예측 및 성능 평가\n",
        "y_pred = voting_clf.predict(test_data)\n",
        "pd.DataFrame(y_pred).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aea67e3",
      "metadata": {
        "id": "6aea67e3",
        "outputId": "c5e62057-6f62-4e7f-a1c1-fdce2dcf848b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target\n",
              "Normal      16298\n",
              "AbNormal     1063\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sub = pd.read_csv(\"submission.csv\")\n",
        "df_sub[\"target\"] = y_pred\n",
        "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
        "df_sub[\"target\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a393bf72",
      "metadata": {
        "id": "a393bf72"
      },
      "outputs": [],
      "source": [
        "# 제출 파일 저장\n",
        "df_sub.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "487205ee-4f70-4fc0-a8f2-a9f8efa46247",
      "metadata": {
        "id": "487205ee-4f70-4fc0-a8f2-a9f8efa46247"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
